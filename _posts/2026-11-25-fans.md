---
layout: distill
title: FANS
description: TBD
date: 2026-04-27
future: true
htmlwidgets: true
hidden: true

# Mermaid diagrams
mermaid:
  enabled: true
  zoomable: true

# Anonymize when submitting
authors:
  - name: Anonymous

# must be the exact same name as your blogpost
bibliography: 2026-11-25-fans.bib

# Add a table of contents to your post.
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - please use this format rather than manually creating a markdown table of contents.
toc:
  - name: Equations
  - name: Images and Figures
    subsections:
      - name: Interactive Figures
  - name: Citations
  - name: Footnotes
  - name: Code Blocks
  - name: Diagrams
  - name: Tweets
  - name: Layouts
  - name: Other Typography?

---

### Plan

## Motivations

Diffusion models have achived state of the art performances on data modalities like Stable diffusion for images, Sora for videos, RFdiffusion for protiens and Mattergen for materials [cite]. They work by learning to reverse a gradual noising process. In a **Forward Pass**  the data modality is progressively corrupted with gaussian noise until it becomes complete noise. In the **backward process** the model learns a denoiser which start from a gaussian noise and denoise this step-by-step to get an apprxomately clean sample. While this framework has proven to be quite effective, the existing works treats the noise and spatially uniform gaussian noise $$\mathcal{N}(\mu, \sigma^2)$$.  

The modalities mentioned above have one thing in common. They exibits __power law__ in their Fouries representation. That is, the low-frequency components have orders of magnitude higher variance than high-frequency components [cite][image]. To interpret the fourier component through visual representation, low frequencies capture the global structure while the high frequency encodes the finer details. On viewing diffusion though the fouries lens of the data, it has an important implications: The DDPM **[make diffusion to DDPM and define earlier in text]** forward process noises high-frequency components substantially earlier and faster as compared to the low frequency components. This can be attributed to the fact that Gaussian noise is applied irrespective of the data's spectral content as we show later.

Since the introduced Gaussian noise is agnostic to the data's spectral characteristics, the forward process thereby imposes a hierarchy of frequencies during generation. As the higher frequencies are noised earler and faster in the forward process, and DDPM learns to reverse this forward process: during backward process the higher frequencies are generated later conditioned on the forward process[give a figure]. Previous work has observed this phenomenon of imposed hierarchy of frequencies during generation[cite flake]

Images aren't spectrally flat. Natural images concentrate most of their power in lower frequencies following characteristic power-law distributions[give image example], while images from domains like Astronomy, Texture Design have varied concentration of pwer across the frequency bands[give image example]. This raises a fundamental question: if datasets have inherent frequency biases and the denoising trajectory naturally progresses from coarse-to-fine structure, why do we apply the same uniform white noise at every timestep and across all frequencies? How does this same uniform white noise across all frequencies perform across images form varied domain? Our research asks whether we can explicitly shape the noise spectrum to (i) match each dataset's actual frequency distribution and (ii) implement a principled time-frequency annealing schedule—shifting from low to high frequencies as denoising progresses—to improve sample quality and training stability without modifying the underlying UNet architecture or DDPM objective.

## Quick Overview

Let's start with a quick overview of the two frameworks we will be working with: Diffusion models and Frequency domain of Images.

### Diffusion Models

### Forward Process

It defines a markov chain that progressively add gaussian noise to the data sample $$\mathbf{x}_0 \sim q(\mathbf{x}_0)$$ over $$T$$ timesteps. Each timestep adds a slight noise to the data resulting in a increasingly noisy samples $$\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_T$$, where $\mathbf{x}_T$ approximates an isotropic Gaussian distribution.
The forward process is formally defined as :

$$
    q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \, \mathbf{x}_{t-1}, \beta_t \mathbf{I}),
$$

where $\beta_t \in (0,1)$ controls the amount of noise added to the data. 

By applying the reparameterization reccursively we obtain the closed form experssion

$$
q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \, \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I}),
$$


where $$\alpha_t = 1 - \beta_t$$ and $$\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$$. 

Thus the noisy data at any given time $$t$$ in the forward proccess

$$
\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{(1 - \bar{\alpha}_t)}\epsilon
$$

where $$\epsilon \in \mathcal{N}(0,\mathbf{I})$$.

A useful notation in this is the log signal-to-noise ration $$\lambda_t = log(\bar{\alpha}_t / (1 - \bar{\alpha}_t))$$ which increases monotonically from 0 ( clean data) to 1 (noise)

### Reverse Process

The Reverse process tries to invert the forward process, transforming Gaussian noise $$\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$ 
back into a data sample resembling the data distribution $$q(\mathbf{x}_0)$$. Since the true reverse transitions 
$$q(\mathbf{x}_{t-1} | \mathbf{x}_t)$$ are intractable, a parameterized model $$p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)$$ 
is trained to approximate them.

The reverse process is modeled as:

$$
p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)),
$$

where $$\boldsymbol{\mu}_\theta$$ and $$\boldsymbol{\Sigma}_\theta$$ are outputs of a neural network conditioned on 
$$\mathbf{x}_t$$ and the timestep $$t$$. The model learns to predict the mean of the denoised sample at each step.

Using the forward process derivation, the true mean of 
$$q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0)$$ can be expressed as:

$$
\boldsymbol{\mu}_q(\mathbf{x}_t, \mathbf{x}_0) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - 
    \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon} \right),
$$

where $$\boldsymbol{\epsilon}$$ denotes the Gaussian noise added at timestep $$t$$. 

On way of learning is during training, the model is optimized to predict this noise directly using a loss of the form:

$$
L(\theta) = 
    \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} 
    \left[ 
        \left\| 
            \boldsymbol{\epsilon} - 
            \boldsymbol{\epsilon}_\theta(
                \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + 
                \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}, t
            ) 
        \right\|^2 
    \right],
$$

which corresponds to a reweighted variational bound on the data likelihood.

### Fouries Domain
Natural Images have rich structures in the frequency domain that is obscured in the pixel space. Understanding this frequency domain perspective is crucial for our investigation.

Let's say we have an image $$x \in \mathbf{R}_{H \times wW\times C}$$. Its pixels are coeefcient of a standard basis $$\mathcal{B} = \{ \mathbf{e}_1, \mathbf{e}_2, \dots, \mathbf{e}_n \} \subset \mathbb{R}^n$$. In the spatial domain, the image is defined as a linear combination of standard basis vectors, where each pixel represents a local real-valued intensity. When we apply the Discrete Fourier Transform(DFT) to this image, it performs unitary change of basis giving us the frequency domain equivalent of the image. The dimension of the fourier and the pixel image remains the same but in fourier domain the coeeficients of the basis becoms complex valued [Give Figure].

For each channel of an image the DFT can be formulated as

$$
F(u, v) = \sum_{x=0}^{H-1} \sum_{y=0}^{W-1} f(x, y) e^{-j 2\pi \left( \frac{ux}{H} + \frac{vy}{W} \right)}
$$

where $$(u,v)$$ aer spatial frequency indices. The radial frequency $$f = \sqrt{u^2 + v^2}$$ measure the distance from the DC ( zero frequency component)

Now, let's sort the Fourier coeeficient $$f(u,v)$$ from low to high frequency. To do so, we start from the center of our Fourier Space and walk in spirals. That is, sort them using the Manhatten distancen of the indices $$(uv,)$$ from the center (0,0) of the Fourier representation. Figure [plot figure] shows the plot of running average of dimension-wise signal variance for images. It's very evident that signal variance decreases rapidly with increasing frquency. [cite fabian paper] shows that similar trend is visible in other doains as well.

**Power Spectral Density(PSD)**: This quantifies how the signal enery is distributed across frequencies. For an image with Fourier Transform $$F(u,v)$$, PSD is defined as :

$$
P(u,v) = |F(u,v)|^2
$$

representing the power at each frequency component. To get one dimensional spectral profile we compute the radially-average PSD by integrating over annular regions at constant radial frequency $$f$$ (simply put average power in ring-shaped zones moving outward from the center). Formally put

$$
P(f) = \frac{1}{|B_f|} \sum{}_{(u,v) \in B_f} |F(u,v)|^2
$$

Where $$B_f$$ is the radial frequency band defined as $$B_f = {(u,v): f \leq \sqrt{u^2+v^2} \le f+ \delta f}$$ and $$\|B_f\|$$ is the number of frequencies in that band.

The PSD reveals how much each frequency contributes to the overall signal. For a dataset of images, we compute per-image PSDs and average them to obtain a dataset-level spectral profile. This aggregate PSD characterizes the typical frequency distribution of the data and captures domain-specific properties

Real-world image datasets exhibit characteristic frequency distributions. The power spectral density of natural images typically follows a power-law decay:

$$ P \propto f^{-\alpha} $$

Emperical studies on natural image statistics shave shown that $$\alpha$$ typically resides in the interval [1,3] <d-cite key="field,physrevLett"> </d-cite>. While Standard photgraphic images generally converges towards $$\alpha \approx 2$$ <d-cite key="vanHateren1992"></d-cite> as we demonstrate in Figure [Give figure], For few domain specific datasets like Astronomy images, we observe this trend $$\alpha \approx 1$$.

To quantify dataset frequency importance, we divide the spectrum into $$B$$ radial frequency bands and compute the normalized band power $$\pi_b$$​ for each band $$B$$:

$$
\pi_b = \frac{1}{N}\sum{N}_{i=1} \frac{\sum{}_{f \in B_i}P_i(f)}{\sum{}_{f} P_i(f)}
$$

where $$N$$ is the number of images in the dataset and $$P_i(f) is the PSD of image $$i$$. These band powers $${\pi_b}^B_{b=1}$$​ form a probability distribution over frequency bands, representing how the dataset's signal energy is distributed across the spectrum.

### Diffusion in Frequency Domain

As we are trying to investigate how the DDPMs inductive bias in the forward process<d-cite key="falck2025fourierspaceperspectivediffusion"></d-cite> affects datasets for varying spectral power density, we can view the DDPM forward process under a chnage of basis to fourier space <d-cite key="dielman,gerdes2024gudgenerationunifieddiffusion"></d-cite>. This is acomplished by applying the Fourier transform $$\mathbf{F}$$ to the variable $$x_t$$

$$
y_t : \mathbf{F}\mathbf{x}_t = \mathbf{F}\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \mathbf{F}\sqrt{(1 - \bar{\alpha}_t)}\epsilon
$$

Here, $$y_t$$ is our fourier-transformed intermediate step at time step $$t$$ of the forward process.

Taking the quantification of Signal-to-noise Ration from <d-cite key="falck2025fourierspaceperspectivediffusion"></d-cite>, where SNR of $$(x_t)_i$$ is the signal to noise ration of frquescy $$i$$ at timestep $$t$$. Formally put

$$
 SNR((x_t)_i) = \frac{\bar{\alpha_t}\varsigma_i}{1-\bar{\alpha_t}}
$$

Where $$\varsigma_i = Var(x_0)_i$$ represents the signal variance of requency $$i$$.


Tying these all together, we see in Figure [Give that heatmap figure ], that standard DDPM corrupts high-frequencies faster than low frequencies. This bias is carry forwarded to the reverse process as well. [rethink this as per pdf]

Thus we want to design a noising schedule that respects the datasets spectral signature. 


## FANS
## Data Generation
**Need for synthetic data**
- PBLT
- EGM
**Real World data**
- Multimodal Universe
- Texture dataset
Results
- show closeup
- show bands of regenerated image
- FID on real world data
- qualitative samples of the real data
